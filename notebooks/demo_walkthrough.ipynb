
```python
# Cell 1
"""
# rPPG Self-Supervised Learning - Interactive Demo

âš ï¸ **DEMONSTRATION ONLY** - No real data, for technical showcase only

This notebook demonstrates the technical capabilities of the remote photoplethysmography system.
"""

# Cell 2
import sys
import os
sys.path.append('../')

import torch
import numpy as np
import matplotlib.pyplot as plt
from src.models.physnet import PhysNet
from src.utils.signal_processing import hr_fft_small_Fs_internal

print("ğŸ¯ rPPG Demo Initialized")
print("ğŸ“¦ All dependencies loaded successfully")

# Cell 3
"""
## 1. Model Architecture Overview

The PhysNet model uses 3D CNNs to extract spatiotemporal features from facial videos.
"""

model = PhysNet(S=2, in_ch=3)
total_params = sum(p.numel() for p in model.parameters())

print(f"ğŸ§  Model: PhysNet")
print(f"ğŸ“Š Parameters: {total_params:,}")
print(f"ğŸ”§ Spatial dimension: 2x2")
print(f"ğŸ“º Input: RGB video (B, 3, T, H, W)")
print(f"â¤ï¸ Output: rPPG signals (B, 5, T)")

# Cell 4
"""
## 2. Synthetic Data Generation

Creating realistic synthetic physiological signals for demonstration.
"""

def generate_synthetic_bvp(heart_rate=70, duration=10, fps=30):
    """Generate synthetic blood volume pulse signal."""
    t = np.linspace(0, duration, int(duration * fps))
    frequency = heart_rate / 60.0
    
    # Primary cardiac frequency + harmonics + noise
    signal = (np.sin(2 * np.pi * frequency * t) + 
             0.3 * np.sin(2 * np.pi * frequency * 2 * t) +
             0.1 * np.random.randn(len(t)))
    
    return t, signal

# Generate example signals
t1, bvp1 = generate_synthetic_bvp(heart_rate=65, duration=10)
t2, bvp2 = generate_synthetic_bvp(heart_rate=85, duration=10)

# Visualize
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))

ax1.plot(t1[:150], bvp1[:150], 'b-', linewidth=1.5)
ax1.set_title('Synthetic BVP Signal - 65 BPM')
ax1.set_ylabel('Amplitude')
ax1.grid(True, alpha=0.3)

ax2.plot(t2[:150], bvp2[:150], 'r-', linewidth=1.5)
ax2.set_title('Synthetic BVP Signal - 85 BPM')
ax2.set_xlabel('Time (seconds)')
ax2.set_ylabel('Amplitude')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Cell 5
"""
## 3. Model Inference Demo

Demonstrating model inference with synthetic video data.
"""

# Create synthetic video input
batch_size = 1
time_frames = 300
video_input = torch.randn(batch_size, 3, time_frames, 128, 128)

print(f"ğŸ“¹ Input video shape: {video_input.shape}")

# Model inference
model.eval()
with torch.no_grad():
    output = model(video_input)
    rppg_extracted = output[0, -1, :].numpy()  # Extract averaged rPPG

print(f"â¤ï¸ Extracted rPPG shape: {rppg_extracted.shape}")

# Estimate heart rate
estimated_hr, psd, freq = hr_fft_small_Fs_internal(rppg_extracted, 30, 1800)
print(f"ğŸ’“ Estimated heart rate: {estimated_hr} BPM")

# Cell 6
"""
## 4. Frequency Domain Analysis

Analyzing the extracted signal in frequency domain to estimate heart rate.
"""

# Plot results
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

# Time domain
ax1.plot(rppg_extracted[:300], 'g-', linewidth=1.5)
ax1.set_title(f'Extracted rPPG Signal (Estimated HR: {estimated_hr} BPM)')
ax1.set_xlabel('Frame')
ax1.set_ylabel('Amplitude')
ax1.grid(True, alpha=0.3)

# Frequency domain
freq_hz = freq[:len(psd)] / 60  # Convert to Hz
ax2.plot(freq_hz[:100], psd[:100], 'purple', linewidth=1.5)
ax2.axvline(x=estimated_hr/60, color='red', linestyle='--', 
           label=f'Estimated: {estimated_hr} BPM')
ax2.set_title('Power Spectral Density')
ax2.set_xlabel('Frequency (Hz)')
ax2.set_ylabel('Power')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Cell 7
"""
## 5. Technical Achievements Summary

This demonstration showcases:
"""

achievements = {
    "ğŸ§  Deep Learning": "3D CNN architecture for spatiotemporal processing",
    "ğŸ”¬ Signal Processing": "FFT-based heart rate estimation",
    "ğŸ¯ Self-Supervised": "Frequency domain consistency learning", 
    "ğŸš€ Performance": "Real-time inference capability",
    "ğŸ›¡ï¸ Privacy": "Anonymization for healthcare data",
    "âš¡ Scalability": "Distributed training support",
    "ğŸ”§ Engineering": "Professional code quality and testing"
}

for skill, description in achievements.items():
    print(f"{skill}: {description}")

print("\n" + "="*60)
print("ğŸ¯ Technical demonstration completed successfully!")
print("ğŸ’¼ Code showcases healthcare AI research capabilities")
print("ğŸ›¡ï¸ No confidential information - demonstration only")
print("="*60)
```
